 MQ 全称为 Message Queue，即消息队列，它是一种应用程序之间的通信方法.
● RabbitMQ包括五种队列模式，简单队列、工作队列、发布/订阅、路由、主题、rpc等。项目中用路由和主题模式比较多
● 有消息确认机制
  a. 模式1：自动确认
  b. 模式2：手动确认
● 有持久化机制，提供交换机和队列的持久化
  a. 持久化：将交换机或队列数据保存到磁盘，服务器宕机或者重启之后数据依然存在。
  b. 非持久化：将交换机或队列数据保存到磁盘到内存，服务器宕机或者重启之后数据会丢失
消息队列有什么优缺点？RabbitMQ有什么优缺点？
优点:
● 应用解耦:通过消息中间件，让系统和系统之间耦合度降低，系统B出现问题，不会导致依赖它的系统A出现问题
● 异步处理:通过消息中间件，让两个操作由串行变为并行，提高吞吐量;
● 流量削峰:通过消息中间件，让需要处理的请求，先进入消息队列缓冲，然后在进行消费。
● 缺点：
● 系统可用性降低
   本来系统运行好好的，现在你非要加入个消息队列进去，那消息队列挂了，你的系统不是呵呵了。因此，系统可用性会降低；
● 系统复杂度提高
   加入了消息队列，要多考虑很多方面的问题，比如：一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。因此，需要考虑的东西更多，复杂性增大。
● 一致性问题
    A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。

谈谈rabbitmq中的延迟队列？
1. 延迟队列存储的是延迟消息，延迟消息是指消息被发送以后，并不想让消费者立刻拿到消息，而是等待待定时间后，消费者拿到消息进行消息
2. 在AMQP协议和RabbitMQ中并没有直接支持延迟队列，但是可以通过DLX和TTL模拟延迟队列。
3. 有什么业务场景？
  a. 订单业务：在电商中，用户下单后30分钟后未付款则取消订单。
  b. 短信通知：用户下单并付款后，1分钟后发短信给用户。
谈谈rabbitmq中的死信队列？
1. 那什么消息是死信(dead message)呢？
  a. 被拒绝（basic.reject或basic.nack）并且requeue=false的消息
  b. TTL过期消息的消息
  c. 队列达到最大长度（队列满了，无法再添加数据到mq中）的消息
2. DLX（Dead Letter Exchanges）死信队列，本身也是一个普通的消息队列，在创建队列的时候，通过设置一些关键参数x-dead-letter-exchange，可以将一个普通的消息队列设置为死信队列
3. 当这个队列中有死信时, RabbitMQ就会自动将这个消息重新发布到设置的Exchange上去, 进而被路由到另一个队列
谈谈rabbitmq中重试机制？
1. 默认情况下，如果消费者程序出现异常情况， Rabbitmq 会自动实现补偿机制 也就是重试机制，会一直重试到不抛出异常为准
2. 默认是5s重试一次，重试策略可以修改
  a. 最大重试次数（默认无数次）
  b. 重试间隔次数
3. 可以设置应答模式，默认是自动应答，可以采取手动应答
谈谈你对rabbitmq消息确认机制的理解？
1. 为什么需要消息确认机制？
  a. 生产者 —>队列—>消费者，中间多了一些环节，这也就造成了消息能否最终发送并被消费成功的不确定性，正是这种不确定性使得我们在使用的时候会关注消息到每一步的时候的状态，
  也就产生了消息的确认机制
2. 哪些情况可能导致消息失败？
  a. 投递失败，producer投递到exchange的时候失败
  b. 路由失败，exchange没有找到对应的队列
  c. 消费失败，消费者没有成功消费消息
如何保证消息不被重复消费？或者说，如何保证消息消费时的幂等性？
先说为什么会重复消费：正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；
但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。
针对以上问题，一个解决思路是：保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响；保证消息等幂性；
比如：在写入消息队列的数据做唯一标示，消费消息时，根据唯一标识判断是否消费过；

1. 什么是幂等性？
  a. 就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。
  b. 比如你有个系统，消费一条往，数据库里插入一条，如果消息重复两次，就插入了两条数据，这就不对了。但是你要是消费到第二次的时候，自己判断一下已经消费过了，直接扔了，
  就保留一条数据，这就是保证了系统的幂等性。
2. 如何保证消费的幂等性？需要根据具体业务
  a. 比如拿到数据要写库，可以先根据主键查一下，如果数据有，就不插入，update一下
  b. 比如你是写redis，反正每次都是set，天然幂等性
  c. 如果是其他场景，需要让生产者发送每条数据的时候，里面加一个全局唯一的id（message可以设置id，比如用uuid就是可以的），类似订单id之类的东西，然后你这里消费到了之后，
  先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。

RabbitMQ如何保证消息的顺序性？
问题回答
1. 哪些情况会导致消息错乱？
  a. 一个queue，有多个consumer去消费，这样就会造成顺序的错误
  b. 一个queue对应一个consumer，但是consumer里面进行了多线程消费，这样也会造成消息消费顺序错误。
2. 如何保证消息的顺序性呢？两者方式
  a. 拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；这样也会造成吞吐量下降，可以在消费者内部采用多线程的方式取消费。
  保证生产者 - MQServer - 消费者是一对一对一的关系.

  a. 就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理



RabbitMQ如何保证消息不丢失？

1. 丢消息的情况有3种情况
  a. 生产者丢
  b. rabbitmq丢
  c. 消费端弄丢
2. 如何保证消息不丢失，就是分别避免每一个环节丢失
  a. 保证生产者不丢消息
  b. 保证rabbitmq不丢消息
  c. 保证消费端不丢消息
3. 保证生产者不丢消息，要确保说写rabbitmq的消息别丢，可以开启confirm模式。
  ○ 每次写的消息都会分配一个唯一的id，如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。
  ○ 如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，我们可以重试。
4. 保证消息队列丢数据不丢消息，开启rabbitmq的持久化（持久化queue和message）
  ○ 消息写入之后会持久化到磁盘，假如rabbitmq挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。
  ○ rabbitmq还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。
  ○ 持久化queue，在创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；
  ○ 持久化Message，在发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。
5. 保证消费端不丢消息
  a. 依靠ack机制，简单来说，就是你关闭rabbitmq自动ack，通过一个api来手动ack就行，就是每次你自己代码里确保处理完的时候，在程序里ack一下。

RabbitMQ如何避免消息堆积？
问题回答
1. 为什么出现消息堆积？
  a. 消息堆积主要是生产者和消费者不平衡导致的
2. 核心处理思路还是提高消费者的消费速率，保证消费者不出现消费故障。
3. 哪些方式可以避免消息堆积呢？
  a. 足够的cpu和内存资源（硬件）
  b. 消费者数量足够多
  c. 避免消费者故障，举个例子，消费端每次消费之后要写MySQL，结果MySQL挂了，消费端卡那儿了，不动了。或者是消费端出了个什么叉子，导致消费速度极其慢。
4. 如果发现了大量消息堆积如何解决呢？
  a. 如果消息不是很多，修复consumer的问题，重先上线consumer就好了，
  b. 如果消息很多，有100w，1000w条，那就临时紧急扩容处理
    ⅰ. 先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉
    ⅱ. 新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量
    ⅲ. 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue
    ⅳ. 接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据
    ⅴ. 这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据
    ⅵ. 等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息
